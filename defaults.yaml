name: "attention_rnn"
shrink_dataset_by: 5
n_epochs: 100
batch_size: 100
hidden_dim: 256
n_patches: 4
patch_shape: [8, 8]
area_dim: 128
n_classes: 10
n_channels: 1
# whether patch should go through a convnet or an fcnet
convolutional: False
learning_rate: 1e-3
batched_window: True
